# Session 11 - GRU, Attention Mechanism & Transformers

Attention is all you need!



* [video](https://youtu.be/HR3GY8OGeK0)

# Assignment:

1. Look at this [file (Links to an external site.)](https://bastings.github.io/annotated_encoder_decoder/)
2. Re-implement this and move to lambda. Provide the option to provide German text and get English text back. 

# Results:

### Performance :

<img src="snips\attention-model-performance.png" alt="performance" style="zoom:80%;" />

<img src="snips\1.png" alt="performance" style="zoom:80%;" />



<img src="snips\2.png" alt="performance" style="zoom:80%;" />



<img src="snips\3.png" alt="performance" style="zoom:80%;" />



<img src="snips\inf.png" alt="performance" style="zoom:80%;" />







